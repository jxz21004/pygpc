{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nOpenMP and CUDA\n===============\n\nAccelerating pygpc by using different computing backends\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nThis tutorial shows how to accelerate pygpc by choosing different computing backends.\nAt the moment, the following backends are available:\n\n1. Implementation in **Python**: pygpc names this backend **python**\n2. Implementation in **C++**: pygpc names this backend **cpu**\n3. Implementation in **C++** and **OpenMP**: pygpc names this backend **omp**\n4. Implementation in **CUDA-C++**: pygpc names this backend **cuda**, an Nvidia GPU is required\n\nInstallation of the CUDA backend\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nPygpc also provides a CUDA-backend to speed up some computations. To use the backend you need to build it manually.\nThis requires the CUDA-toolkit and CMake. CMake can be installd via the `pip` command.\nSimply run the following command in your terminal:\n\n.. code-block:: bash\n\n  pip install cmake\n\nFor the installation of the CUDA-toolkit please refer to:\nhttps://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html.\nIf CMake and the CUDA-toolkit are installed on your machine you can build the extension with:\n\n.. code-block:: bash\n\n  python build_pygpc_extensions_cuda.py\n\n**Troubleshooting for OSX:**\n\nOn a mac you need GCC to install pygpc. If you are using the `brew` package manager you can simply run:\n\n.. code-block:: bash\n\n  brew install gcc libomp\n\nThen install pygpc with:\n\n.. code-block:: bash\n\n  CC=gcc-9 CXX=g++-9 python setup.py install\n\nSetting up benchmark parameters\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nWe define the number of samples, the dimensionality of the parameter space and the maximum number of basis functions.\nThis will determine the size of the gPC matrix and therefore the compute time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_dim = 4               # number of random variables (defines total number of basis functions)\nn_basis_order = 8       # polynomial approximation order (defines total number of basis functions with n_dim)\nn_samples = 100000      # number of random samples (number of rows in gPC matrix))\nn_qoi = 100             # number of QOIs (number of columns in gPC coefficient matrix)\nn_iterations = 3        # number repeated benchmark runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting up the gPC and the grid of sampling points\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pygpc\nimport numpy as np\nfrom collections import OrderedDict\n\n# define model\nmodel = pygpc.testfunctions.DiscontinuousRidgeManufactureDecay()\n\n# define parameters\nparameters = OrderedDict()\nfor i_dim in range(n_dim):\n    parameters[\"x\"+str(i_dim)] = pygpc.Beta(pdf_shape=[1, 1], pdf_limits=[1.2, 2])\n\n# define problem\nproblem = pygpc.Problem(model, parameters)\n\n# define grid\noptions = dict()\ngrid = pygpc.Random(parameters_random=problem.parameters_random,\n                                      n_grid=n_samples,\n                                      options={\"n_grid\": n_samples, \"seed\": 1})\n\n# define gPC\ngpc = pygpc.Reg(problem=problem,\n                order=[n_basis_order] * n_dim,\n                order_max=n_basis_order,\n                order_max_norm=1,\n                interaction_order=n_dim,\n                interaction_order_current=n_dim,\n                options=options)\n\ngpc.grid = grid\n\n# get number of basis functions\nn_basis = pygpc.get_num_coeffs_sparse([n_basis_order] * n_dim, n_basis_order, n_dim, n_dim, n_dim, 1)\n\n# create coefficient matrix\ncoeffs = np.ones((len(gpc.basis.b), n_qoi))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the benchmark\n^^^^^^^^^^^^^^^^^^^^^\nPer default the **omp**-backend is set. Let's try them all and see how the performance changes.\nIf you have installed the CUDA backend you can add \"cuda\" to the list of backends.\nIt is the fastest one and outperforms all other backends.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nbackends = [\"python\", \"cpu\", \"omp\"]  # \"cuda\"\nlabels = [\"Python\", \"C++\", \"C++ OpenMP\"]  # \"CUDA\"\n\ntime_create_gpc_matrix = OrderedDict()\ntime_get_approximation = OrderedDict()\n\nfor b in backends:\n    time_create_gpc_matrix[b] = []\n    time_get_approximation[b] = []\n\n# warmup to wake gpu up from idle\nif \"cuda\" in backends:\n    for _ in range(10):\n        gpc.backend = \"cuda\"\n        gpc.create_gpc_matrix(b=gpc.basis.b, x=gpc.grid.coords_norm)\n\n# benchmark\nfor _ in range(n_iterations):\n    # python backend\n    for b in backends:\n        gpc.backend = b\n\n        # benchmark create_gpc_matrix\n        start = time.time()\n        gpc.create_gpc_matrix(b=gpc.basis.b, x=gpc.grid.coords_norm)\n        stop = time.time()\n        time_create_gpc_matrix[b].append(stop - start)\n\n        # benchmark get_approximation\n        start = time.time()\n        gpc.get_approximation(coeffs, x=gpc.grid.coords_norm)\n        stop = time.time()\n        time_get_approximation[b].append(stop - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Performance comparison between the backends\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom matplotlib import patches as mpatches\n\n# plot results\npatches_muted = []\npatches_pastel = []\nfor ind, b in enumerate(backends):\n    plt.bar(ind, np.mean(time_get_approximation[b]),\n            yerr=np.std(time_get_approximation[b]),\n            color=sns.color_palette(\"muted\", len(backends))[ind])\n    plt.bar(ind, np.mean(time_create_gpc_matrix[b]),\n            yerr=np.std(time_create_gpc_matrix[b]),\n            color=sns.color_palette(\"pastel\", len(backends))[ind])\n    patches_muted.append(mpatches.Patch(\n        color=sns.color_palette(\"muted\", len(backends))[ind],\n        label=\"get_approximation (\" + labels[ind] + \")\"))\n    patches_pastel.append(mpatches.Patch(\n        color=sns.color_palette(\"pastel\", len(backends))[ind],\n        label=\"create_gpc_matrix (\" + labels[ind] + \")\"))\n\nplt.ylabel(\"Computation time in s\")\nplt.xticks(range(len(labels)), labels)\nplt.title(\"Number of samples: {}, Number of basis functions: {}\".format(n_samples, n_basis))\n_ = plt.legend(handles=patches_pastel + patches_muted)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}