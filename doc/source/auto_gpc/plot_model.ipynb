{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSetting up your model\n=====================\nIn order to analyze your model with pygpc, it has to be converted into a format understandable for pygpc.\nFor this, we implemented the *AbstracModel* class in pygpc. You can find an example template in\n`/templates/MyModel.py <../../../../templates/MyModel.py>`_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport inspect\nfrom pygpc.AbstractModel import AbstractModel\n\n\nclass MyModel(AbstractModel):\n    \"\"\"\n    MyModel evaluates something. The parameters of the model (constants and random parameters) are stored in the\n    dictionary p. Their type is defined during the problem definition.\n\n    Parameters\n    ----------\n    p[\"x1\"] : float or ndarray of float [n_grid]\n        Parameter 1\n    p[\"x2\"] : float or ndarray of float [n_grid]\n        Parameter 2\n    p[\"x3\"] : float or ndarray of float [n_grid]\n        Parameter 3\n\n    Returns\n    -------\n    y : ndarray of float [n_grid x n_out]\n        Results of the n_out quantities of interest the gPC is conducted for\n    additional_data : dict or list of dict [n_grid]\n        Additional data, will be saved under its keys in the .hdf5 file during gPC simulations.\n        If multiple grid-points are evaluated in one function call, return a dict for every grid-point in a list\n    \"\"\"\n\n    def __init__(self):\n        self.fname = inspect.getfile(inspect.currentframe())\n\n    def validate(self):\n        pass\n\n    def simulate(self, process_id=None, matlab_engine=None):\n\n        y = self.p[\"x1\"] * self.p[\"x2\"] * self.p[\"x3\"]\n        y = y[:, np.newaxis]\n\n        additional_data = [{\"additional_data/info_1\": [1, 2, 3],\n                            \"additional_data/info_2\": [\"some additional information\"]}]\n        additional_data = y.shape[0] * additional_data\n\n        return y, additional_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The actual computations are taking place in the method *simulate*. In this example, we simply multiply\nthe parameters *x1*, *x2* and *x3* and return the output. During gPC, multiple simulations have to be performed\nfor some parameter combinations. For every sampling point, pygpc initializes a new model instance and\npasses a dictionary *p* containing the parameter names together with their values in this model run.\nThis dictionary is stored in the model (self) and can be accessed with the same parameter names\ndefined during the problem definition (*self.p[\"variable_name\"]*).\n\nIn some cases your model may generate additional data alongside your quantity of interest (QOI).\nYou can store this data for later use in the dictionary *additional_data*. This data will be saved for every sampling\npoint in the resulting .hdf5 file.\n\nAt the end, the QOI is returned together with the additional data.\n\nTesting the model\n^^^^^^^^^^^^^^^^^\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pygpc\nimport numpy as np\nfrom collections import OrderedDict\nimport matplotlib.pyplot as plt\n\n# initializing the model\nmodel = MyModel()\n\n# initializing the problem with 2 uniform distributed random parameters\nparameters = OrderedDict()\nparameters[\"x1\"] = pygpc.Beta(pdf_shape=[1, 1], pdf_limits=[-1, 1])\nparameters[\"x2\"] = pygpc.Beta(pdf_shape=[1, 1], pdf_limits=[-1, 1])\nparameters[\"x3\"] = 1.\nproblem = pygpc.Problem(model=model, parameters=parameters)\n\n# generating a 100x100 2D tensored grid\nx1_arr = np.linspace(-1, 1, 100)\nx2_arr = np.linspace(-1, 1, 100)\n\nx1, x2 = np.meshgrid(x1_arr, x2_arr)\n\n# flattening the grid to [(100*100) x 2] (random parameters only)\nsampling_points = np.hstack((x1.flatten()[:, np.newaxis],\n                             x2.flatten()[:, np.newaxis]))\n\n# initializing Computation class\n# n_cpu = 0 : use this if the model is capable of to evaluate all sampling points in parallel\n# n_cpu = 1 : the model is called in serial for every sampling point.\n# n_cpu > 1 : A multiprocessing.Pool will be opened and n_cpu sampling points are calculated in parallel\ncom = pygpc.Computation(n_cpu=0)\n\n# running the model\nres = com.run(model=model,\n              problem=problem,\n              coords=sampling_points,\n              coords_norm=sampling_points,\n              i_iter=None,\n              i_subiter=None,\n              fn_results=None,\n              print_func_time=None)\n\n# plotting results\nfig = plt.figure(figsize=(7, 5))\nax = fig.add_subplot(1, 1, 1, projection='3d')\n\nim = ax.plot_surface(x1, x2,\n                     np.reshape(res[:, 0], (x2_arr.size, x1_arr.size), order='c'),\n                     cmap=\"jet\")\n\nax.set_ylabel(r\"$x_2$\", fontsize=16)\nax.set_xlabel(r\"$x_1$\", fontsize=16)\nfig.colorbar(im, ax=ax, orientation='vertical')\nax.set_title(\"MyModel function\")\nplt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}